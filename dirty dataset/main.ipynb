{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary data from a salary survey that contains completely unworkable data - with the purpose of cleaning it up to be used for a dashboard displaying the information and for gathering insights. df_filtered is the final dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning dirty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>What industry do you work in?</th>\n",
       "      <th>Job title</th>\n",
       "      <th>If your job title needs additional context, please clarify here:</th>\n",
       "      <th>What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)</th>\n",
       "      <th>How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.</th>\n",
       "      <th>Please indicate the currency</th>\n",
       "      <th>If \"Other,\" please indicate the currency here:</th>\n",
       "      <th>If your income needs additional context, please provide it here:</th>\n",
       "      <th>What country do you work in?</th>\n",
       "      <th>If you're in the U.S., what state do you work in?</th>\n",
       "      <th>What city do you work in?</th>\n",
       "      <th>How many years of professional work experience do you have overall?</th>\n",
       "      <th>How many years of professional work experience do you have in your field?</th>\n",
       "      <th>What is your highest level of education completed?</th>\n",
       "      <th>What is your gender?</th>\n",
       "      <th>What is your race? (Choose all that apply.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp How old are you?  What industry do you work in?  \\\n",
       "0  4/27/2021 11:02:10            25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22            25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38            25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41            25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42            25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                  Job title  \\\n",
       "0        Research and Instruction Librarian   \n",
       "1  Change & Internal Communications Manager   \n",
       "2                      Marketing Specialist   \n",
       "3                           Program Manager   \n",
       "4                        Accounting Manager   \n",
       "\n",
       "  If your job title needs additional context, please clarify here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  \\\n",
       "0                                             55,000                                                                                                                                                                                     \n",
       "1                                             54,600                                                                                                                                                                                     \n",
       "2                                             34,000                                                                                                                                                                                     \n",
       "3                                             62,000                                                                                                                                                                                     \n",
       "4                                             60,000                                                                                                                                                                                     \n",
       "\n",
       "   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.  \\\n",
       "0                                                0.0                                                                                                                                                \n",
       "1                                             4000.0                                                                                                                                                \n",
       "2                                                NaN                                                                                                                                                \n",
       "3                                             3000.0                                                                                                                                                \n",
       "4                                             7000.0                                                                                                                                                \n",
       "\n",
       "  Please indicate the currency  \\\n",
       "0                          USD   \n",
       "1                          GBP   \n",
       "2                          USD   \n",
       "3                          USD   \n",
       "4                          USD   \n",
       "\n",
       "  If \"Other,\" please indicate the currency here:   \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "  If your income needs additional context, please provide it here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What country do you work in?  \\\n",
       "0                United States   \n",
       "1               United Kingdom   \n",
       "2                           US   \n",
       "3                          USA   \n",
       "4                           US   \n",
       "\n",
       "  If you're in the U.S., what state do you work in? What city do you work in?  \\\n",
       "0                                     Massachusetts                    Boston   \n",
       "1                                               NaN                 Cambridge   \n",
       "2                                         Tennessee               Chattanooga   \n",
       "3                                         Wisconsin                 Milwaukee   \n",
       "4                                    South Carolina                Greenville   \n",
       "\n",
       "  How many years of professional work experience do you have overall?  \\\n",
       "0                                          5-7 years                    \n",
       "1                                       8 - 10 years                    \n",
       "2                                        2 - 4 years                    \n",
       "3                                       8 - 10 years                    \n",
       "4                                       8 - 10 years                    \n",
       "\n",
       "  How many years of professional work experience do you have in your field?  \\\n",
       "0                                          5-7 years                          \n",
       "1                                          5-7 years                          \n",
       "2                                        2 - 4 years                          \n",
       "3                                          5-7 years                          \n",
       "4                                          5-7 years                          \n",
       "\n",
       "  What is your highest level of education completed? What is your gender?  \\\n",
       "0                                    Master's degree                Woman   \n",
       "1                                     College degree           Non-binary   \n",
       "2                                     College degree                Woman   \n",
       "3                                     College degree                Woman   \n",
       "4                                     College degree                Woman   \n",
       "\n",
       "  What is your race? (Choose all that apply.)  \n",
       "0                                       White  \n",
       "1                                       White  \n",
       "2                                       White  \n",
       "3                                       White  \n",
       "4                                       White  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data \n",
    "import pandas as pd\n",
    "df = pd.read_csv('salary_survey.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'How old are you?', 'What industry do you work in?',\n",
       "       'Job title',\n",
       "       'If your job title needs additional context, please clarify here:',\n",
       "       'What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)',\n",
       "       'How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.',\n",
       "       'Please indicate the currency',\n",
       "       'If \"Other,\" please indicate the currency here: ',\n",
       "       'If your income needs additional context, please provide it here:',\n",
       "       'What country do you work in?',\n",
       "       'If you're in the U.S., what state do you work in?',\n",
       "       'What city do you work in?',\n",
       "       'How many years of professional work experience do you have overall?',\n",
       "       'How many years of professional work experience do you have in your field?',\n",
       "       'What is your highest level of education completed?',\n",
       "       'What is your gender?', 'What is your race? (Choose all that apply.)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>job title</th>\n",
       "      <th>job_title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>income_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>professional_experience_overall</th>\n",
       "      <th>professional_experience_in_specified_field</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>research and instruction librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>change &amp; internal communications manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>marketing specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>program manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>accounting manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                       industry  \\\n",
       "0  4/27/2021 11:02:10  25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22  25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38  25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41  25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42  25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                  job title job_title_context  salary  \\\n",
       "0        research and instruction librarian               NaN  55,000   \n",
       "1  change & internal communications manager               NaN  54,600   \n",
       "2                      marketing specialist               NaN  34,000   \n",
       "3                           program manager               NaN  62,000   \n",
       "4                        accounting manager               NaN  60,000   \n",
       "\n",
       "   compensation currency other_currency income_context         country  \\\n",
       "0           0.0      USD            NaN            NaN   United States   \n",
       "1        4000.0      GBP            NaN            NaN  United Kingdom   \n",
       "2           NaN      USD            NaN            NaN              US   \n",
       "3        3000.0      USD            NaN            NaN             USA   \n",
       "4        7000.0      USD            NaN            NaN              US   \n",
       "\n",
       "            state         city professional_experience_overall  \\\n",
       "0   Massachusetts       Boston                       5-7 years   \n",
       "1             NaN    Cambridge                    8 - 10 years   \n",
       "2       Tennessee  Chattanooga                     2 - 4 years   \n",
       "3       Wisconsin    Milwaukee                    8 - 10 years   \n",
       "4  South Carolina   Greenville                    8 - 10 years   \n",
       "\n",
       "  professional_experience_in_specified_field        education      gender  \\\n",
       "0                                  5-7 years  Master's degree       Woman   \n",
       "1                                  5-7 years   College degree  Non-binary   \n",
       "2                                2 - 4 years   College degree       Woman   \n",
       "3                                  5-7 years   College degree       Woman   \n",
       "4                                  5-7 years   College degree       Woman   \n",
       "\n",
       "    race  \n",
       "0  White  \n",
       "1  White  \n",
       "2  White  \n",
       "3  White  \n",
       "4  White  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming columns\n",
    "df = df.rename(columns={'Job title':'job title'})\n",
    "df = df.rename(columns={'Timestamp':'timestamp'})   \n",
    "df = df.rename(columns={'Please indicate the currency':'currency'})  \n",
    "df = df.rename(columns={'How old are you?':'age'})\n",
    "df = df.rename(columns={'What industry do you work in?':'industry'})\n",
    "df = df.rename(columns={'If your job title needs additional context, please clarify here:':'job_title_context'})\n",
    "df = df.rename(columns={'How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.':'compensation'})\n",
    "df = df.rename(columns={'What is your annual salary? (You\\'ll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)':'salary'})\n",
    "df = df.rename(columns={'If \\\"Other,\\\" please indicate the currency here: ':'other_currency'})\n",
    "df = df.rename(columns={'If your income needs additional context, please provide it here:':'income_context'})\n",
    "df = df.rename(columns={'What country do you work in?':'country'})\n",
    "df = df.rename(columns={'If you\\'re in the U.S., what state do you work in?':'state'})\n",
    "df = df.rename(columns={'What city do you work in?':'city'})\n",
    "df = df.rename(columns={'How many years of professional work experience do you have overall?':'professional_experience_overall'})\n",
    "df = df.rename(columns={'How many years of professional work experience do you have in your field?':'professional_experience_in_specified_field'})\n",
    "df = df.rename(columns={'What is your highest level of education completed?':'education'})\n",
    "df = df.rename(columns={'What is your gender?':'gender'})\n",
    "df = df.rename(columns={'What is your race? (Choose all that apply.)':'race'})\n",
    "\n",
    "\n",
    "# lowing job titles \n",
    "df['job title'] = df['job title'].str.lower()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'age', 'industry', 'job title', 'job_title_context',\n",
       "       'salary', 'compensation', 'currency', 'other_currency',\n",
       "       'income_context', 'country', 'state', 'city',\n",
       "       'professional_experience_overall',\n",
       "       'professional_experience_in_specified_field', 'education', 'gender',\n",
       "       'race'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is there going to be a feasible way to classify context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hourly                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         4\n",
       "Bonus not guaranteed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           3\n",
       "Stock options                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  3\n",
       "RSUs                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           3\n",
       "I get to salary package and reduce my taxable income by $15,900 per year by paying for living expenses before tax - a benefit available for non-profits in Australia. This is approx. $5100 per year less tax for me to pay                                                                                                                                                                                                                                                                                                                                                                                                                                    3\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ..\n",
       "bonuses dependent on personal and company performance                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
       "I am underpaid by $20k for my level of experience                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
       "I didn't calibrate at 40 hours a week because no massage therapist does hands on work for 40 hours a week. There's hourly pay for hands on hours only, and we have to do other work between sessions that is unpaid and folded into what we get paid for the sessions. So officially, a standard workweek is 24 hours a week, and that's what we're paid for, while doing about 18 hours of additional \"unpaid\" prep and charting. Our hourly rate is higher than it would otherwise be to account for these hours. But if I had given my hourly rate times 40 hours it would have come out to something that bore no resemblance to what I actually earn.     1\n",
       "My income is salaried but weekly hourly expectations are 55-60 hours per week.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "Band 2 (of three) of the independent schools multi-enterprise award agreement.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "Name: income_context, Length: 2972, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# viewing data\n",
    "df['income_context'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected, working through salary and compensation fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected = pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathering columns relevant to income\n",
    "selected= df[['compensation','salary','currency','income_context']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected['salary'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working through nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected['compensation'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if null value in comp or salary field, replace with 0 \n",
    "selected.loc[:, 'compensation'] = selected['compensation'].fillna(0)\n",
    "selected.loc[:, 'salary'] = selected['salary'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected['salary'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if salary is 1-3 digits, that means they entered hourly wage. We need to convert this to annual income\n",
    "# hourly * 8 *5*4*12. 1920\n",
    "#selected['salary'] = selected['salary'].apply(lambda x : x*1920 if len(x) < 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\2264406209.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  selected.loc[:, 'salary'] = pd.to_numeric(selected['salary'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "#replace , in salary with blank space\n",
    "selected.loc[:, 'salary'] = selected['salary'].astype(str)\n",
    "selected.loc[:, 'salary'] = selected['salary'].str.replace(',', '')\n",
    "selected.loc[:, 'salary'] = pd.to_numeric(selected['salary'], errors='coerce')\n",
    "selected.loc[:, 'compensation'] = pd.to_numeric(selected['compensation'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected['compensation'].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.799000e+04\n",
       "mean     1.471574e+05\n",
       "std      5.414601e+06\n",
       "min      0.000000e+00\n",
       "25%      5.400000e+04\n",
       "50%      7.500000e+04\n",
       "75%      1.100000e+05\n",
       "max      8.700000e+08\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected['salary'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to convert the hourly salary answers into yearly answers\n",
    "# assuming that every number under 1000 was meant to be hourly and not salary\n",
    "\n",
    "selected.loc[:, 'salary'] = selected['salary'].apply(lambda x: x*1920 if x < 1000 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.799000e+04\n",
       "mean     1.477281e+05\n",
       "std      5.414610e+06\n",
       "min      0.000000e+00\n",
       "25%      5.450000e+04\n",
       "50%      7.600000e+04\n",
       "75%      1.100000e+05\n",
       "max      8.700000e+08\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected['salary'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.loc[:, 'compensation'] = selected['compensation'].round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Adding compensation to salary, going to need to remove the compensation and salary from df and add this one into it !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.loc[:,'total_salary'] = selected['compensation'] + selected['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the worked columns and placing them into main dataframe\n",
    "df['total_salary'] = selected['total_salary']\n",
    "df['salary'] = selected['salary']\n",
    "df['compensation'] = selected['compensation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('total salary', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holding_countries = holding_countries['country'].str.replace(pattern, 'United States',case=False,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one option to change the different usa rows would be to use a mapping function, the next you could\n",
    "# maybe try regex to see if that works?\n",
    "\n",
    "\n",
    "# holding_united = df['country'].replace(country_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'age', 'industry', 'job title', 'job_title_context',\n",
       "       'salary', 'compensation', 'currency', 'other_currency',\n",
       "       'income_context', 'country', 'state', 'city',\n",
       "       'professional_experience_overall',\n",
       "       'professional_experience_in_specified_field', 'education', 'gender',\n",
       "       'race', 'total_salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning expierence columns \n",
    "# a way to split the rows, take 0 and 2 index location \n",
    "# not all values have a space between them \n",
    "# is there going to be a way to pass both dataframes?\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# professional expierence column work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to hold the 2 columns i want to work with\n",
    "professional_experience = df[['professional_experience_overall','professional_experience_in_specified_field']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11 - 20 years       6525\n",
       "5-7 years           6506\n",
       "2 - 4 years         6237\n",
       "8 - 10 years        4966\n",
       "21 - 30 years       1866\n",
       "1 year or less      1469\n",
       "31 - 40 years        381\n",
       "41 years or more      40\n",
       "Name: professional_experience_in_specified_field, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professional_experience['professional_experience_in_specified_field'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11 - 20 years       9604\n",
       "8 - 10 years        5370\n",
       "5-7 years           4871\n",
       "21 - 30 years       3631\n",
       "2 - 4 years         3010\n",
       "31 - 40 years        867\n",
       "1 year or less       515\n",
       "41 years or more     122\n",
       "Name: professional_experience_overall, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professional_experience['professional_experience_overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\354235787.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  professional_experience['professional_experience_overall'] = professional_experience['professional_experience_overall'].map(year_mapping)\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\354235787.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  professional_experience['professional_experience_in_specified_field'] = professional_experience['professional_experience_in_specified_field'].map(year_mapping)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.5    9604\n",
       "9       5370\n",
       "6       4871\n",
       "25.5    3631\n",
       "3       3010\n",
       "35.5     867\n",
       "1        515\n",
       "41       122\n",
       "Name: professional_experience_overall, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# year mapping to replace strings as numeric values in prof exp overall and prof exp in field \n",
    "year_mapping = {\n",
    "'11 - 20 years':'15.5',\n",
    "'8 - 10 years':'9',  \n",
    "'5-7 years': '6',     \n",
    "'21 - 30 years':'25.5',   \n",
    "'2 - 4 years': '3',    \n",
    "'31 - 40 years': '35.5',   \n",
    "'1 year or less': '1', \n",
    "'41 years or more':'41'\n",
    "}\n",
    "\n",
    "professional_experience['professional_experience_overall'] = professional_experience['professional_experience_overall'].map(year_mapping)\n",
    "professional_experience['professional_experience_in_specified_field'] = professional_experience['professional_experience_in_specified_field'].map(year_mapping)\n",
    "professional_experience['professional_experience_overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11 - 20 years       9604\n",
       "8 - 10 years        5370\n",
       "5-7 years           4871\n",
       "21 - 30 years       3631\n",
       "2 - 4 years         3010\n",
       "31 - 40 years        867\n",
       "1 year or less       515\n",
       "41 years or more     122\n",
       "Name: professional_experience_overall, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['professional_experience_overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing rows in df with modified rows \n",
    "df[['professional_experience_overall', 'professional_experience_in_specified_field']] = professional_experience[['professional_experience_overall', 'professional_experience_in_specified_field']]\n",
    "df[['professional_experience_overall', 'professional_experience_in_specified_field']] = df[['professional_experience_overall', 'professional_experience_in_specified_field']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                                      object\n",
       "age                                            object\n",
       "industry                                       object\n",
       "job title                                      object\n",
       "job_title_context                              object\n",
       "salary                                          int64\n",
       "compensation                                  float64\n",
       "currency                                       object\n",
       "other_currency                                 object\n",
       "income_context                                 object\n",
       "country                                        object\n",
       "state                                          object\n",
       "city                                           object\n",
       "professional_experience_overall                object\n",
       "professional_experience_in_specified_field     object\n",
       "education                                      object\n",
       "gender                                         object\n",
       "race                                           object\n",
       "total_salary                                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to convert new dataframe columns to str \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['professional_experience_overall'] = pd.to_numeric(df['professional_experience_overall'], errors='coerce')\n",
    "df['professional_experience_in_specified_field'] = pd.to_numeric(df['professional_experience_in_specified_field'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                                      object\n",
       "age                                            object\n",
       "industry                                       object\n",
       "job title                                      object\n",
       "job_title_context                              object\n",
       "salary                                          int64\n",
       "compensation                                  float64\n",
       "currency                                       object\n",
       "other_currency                                 object\n",
       "income_context                                 object\n",
       "country                                        object\n",
       "state                                          object\n",
       "city                                           object\n",
       "professional_experience_overall               float64\n",
       "professional_experience_in_specified_field    float64\n",
       "education                                      object\n",
       "gender                                         object\n",
       "race                                           object\n",
       "total_salary                                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# they are floats now instead of int because when you mapped the ages you included halfs instead of keeping\n",
    "# whole numbers\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how would you comepare 2 columns, where they may have repeated values but in other cases one is missing. \n",
    "# ie if capital was minneapolis but there was no minnesota in the city column, could you replace it with \n",
    "# minnesota if the value pair already exists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df age column work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_age = df['age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-34         12631\n",
       "35-44          9879\n",
       "45-54          3182\n",
       "18-24          1201\n",
       "55-64           991\n",
       "65 or over       94\n",
       "under 18         12\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holding_age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert holding age to string so we can map it \n",
    "holding_age = holding_age.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make a note that when the age is displayed, it is 65+ for 65 and 18 is actually youth.\n",
    "age_mapping = {'25-34':29.5,        \n",
    "'35-44':39.5,          \n",
    "'45-54' :49.5,         \n",
    "'18-24':21,          \n",
    "'55-64':59.5,           \n",
    "'65 or over':65,       \n",
    "'under 18':18,         }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holding_age.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        29.5\n",
       "1        29.5\n",
       "2        29.5\n",
       "3        29.5\n",
       "4        29.5\n",
       "         ... \n",
       "27985    29.5\n",
       "27986    29.5\n",
       "27987    65.0\n",
       "27988    65.0\n",
       "27989    21.0\n",
       "Name: age, Length: 27990, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holding_age = holding_age.map(age_mapping)\n",
    "holding_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = holding_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Currency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are strings within the other_currency column , need to find a way to push those string column values\n",
    "into income_context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# would there be a way you could select currency column where it only contains other , then you have a dataframe with \n",
    "\n",
    "\n",
    "# work with main dataframe, if other currency column is equal to 3 length long then we can replace it in the currency column \n",
    "# be sure to upper it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_currency = df[['currency', 'other_currency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_currency = holding_currency['other_currency'].value_counts()\n",
    "df_currency = df['currency']\n",
    "df_other_currency = df['other_currency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'age', 'industry', 'job title', 'job_title_context',\n",
       "       'salary', 'compensation', 'currency', 'other_currency',\n",
       "       'income_context', 'country', 'state', 'city',\n",
       "       'professional_experience_overall',\n",
       "       'professional_experience_in_specified_field', 'education', 'gender',\n",
       "       'race', 'total_salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['currency'] = df['currency'].str.upper()\n",
    "df['other_currency'] = df['other_currency'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the other_currency row is already 3 digits, place it in the currency column \n",
    "\n",
    "def replace_currency(row):\n",
    "    other_currency = row['other_currency']\n",
    "    if isinstance(other_currency, str) and len(other_currency) == 3:\n",
    "        return other_currency\n",
    "    else:\n",
    "        return row['currency']\n",
    "\n",
    "df['currency'] = df.apply(replace_currency, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column with 3 letter but a space on the end\n",
    "#df.iloc[24843, df.columns.get_loc('other_currency')] = df.iloc[24843]['other_currency'].replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to capitalize everything because you used upper on second go around\n",
    "# could you add multiple keys for each value to condense text? \n",
    "currency_mapping = {\n",
    "    'TAIWANESE DOLLARS': 'TWD',\n",
    "    'PHILIPPINE PESO': 'PHP',\n",
    "    'KOREAN WON': 'KRW',\n",
    "    'IDR ': 'IDR',\n",
    "    'ILS (SHEKEL)': 'ILS',\n",
    "    'DKK ': 'DKK',\n",
    "    'AUD AUSTRALIAN': 'AUD',\n",
    "    'EQUITY': 'EQUITY',\n",
    "    'ARGENTINIAN PESO (ARS)': 'ARS',\n",
    "    'POLISH ZLOTY': 'PLN',\n",
    "    'INR (INDIAN RUPEE)': 'INR',\n",
    "    'DANISH KRONER': 'DKK',\n",
    "    'KOREAN WON': 'KRW',\n",
    "    'EURO': 'EUR',\n",
    "    'MEXICAN PESOS': 'MXN',\n",
    "    'SINGAPORE DOLLARS': 'SGD',\n",
    "    'THAI BAHT': 'THB',\n",
    "    'RUPEES': 'INR',\n",
    "    'CROATIAN KUNA': 'HRK',\n",
    "    'INDIAN RUPEES': 'INR',\n",
    "    \n",
    "    'BRL (R$)': 'BRL',\n",
    "    'MEXICAN PESOS': 'MXN',\n",
    "    'AMERICAN DOLLARS': 'USD',\n",
    "    'PLN (POLISH ZLOTY)': 'PLN',\n",
    "    'CZECH CROWNS': 'CZK',\n",
    "    'NORWEGIAN KRONER (NOK)': 'NOK',\n",
    "    'ILS/NIS': 'ILS',\n",
    "    'US DOLLAR': 'USD',\n",
    "    'NIS (NEW ISRAELI SHEKEL)': 'ILS',\n",
    "    'PHP (PHILIPPINE PESO)': 'PHP',\n",
    "    'ARGENTINE PESO': 'ARS',\n",
    "    'PHILIPPINE PESOS': 'PHP',\n",
    "    'KOREAN WON ': 'KRW',\n",
    "    'THAI  BAHT': 'THB',\n",
    "    'THAI BAHT ': 'THB',\n",
    "    'PLN (ZWOTY)': 'PLN',\n",
    "    'SINGAPORE DOLLARA': 'SGD',\n",
    "    \n",
    "\n",
    "    'RMB (CHINESE YUAN)':'RMB',\n",
    "    'PESO ARGENTINO':'RMB',\n",
    "    'KRW (KOREAN WON)':'RMB',\n",
    "    'CHINA RMB':'RMB',\n",
    "    'AUD AUSTRALIAN ':'RMB',\n",
    "    'POLISH ZOTY':'RMB',\n",
    "    'PHILIPPINE PESO (PHP)':'RMB',\n",
    "    'AUSTRALIAN DOLLARS ':'RMB',\n",
    "    'ISRAELI SHEKELS':'RMB',\n",
    "    'SGD ':'SGD',\n",
    "    'RM':'MYR',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Add more currency mappings as needed\n",
    "}\n",
    "\n",
    "# Define a function to replace the 'currency' column with 3-digit abbreviations\n",
    "def replace_currency1(row):\n",
    "    if not pd.isna(row['other_currency']):\n",
    "        return currency_mapping.get(row['other_currency'], row['currency'])\n",
    "    return row['currency']\n",
    "\n",
    "df['currency'] = df.apply(replace_currency1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[18843]['other_currency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is going to be a better way to do this in the future. Manually cleaning last 5 rows that had NaN values\n",
    "# in other currency, used location given to determine currency abbreviation to place in both columns - currency and other_currency\n",
    "#\n",
    "\n",
    "# the following is how you would manually change values within rows \n",
    "row_indices = [9344, 18843, 18882, 18904,27959]\n",
    "new_values = ['USD', 'MYR','MYR','USD','INR']\n",
    "df.iloc[row_indices, df.columns.get_loc('other_currency')] = new_values\n",
    "df.iloc[row_indices, df.columns.get_loc('currency')] = new_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# country column work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_countries = df['country']\n",
    "holding_countries = holding_countries.str.strip()\n",
    "holding_countries  = holding_countries.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_countries_value_counts = holding_countries.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there has got to be a way using some form of regex that you can find some sort of pattern that\n",
    "# would allow you to do this process wihtout it being so ugly or such a pain\n",
    "country_mapping = {\n",
    "    'america':'united states',\n",
    "    'usa':'united states',\n",
    "    'us':'united states',\n",
    "    'u.s.':'united states',\n",
    "    'usa':'united states',\n",
    "    'united states of america':'united states',\n",
    "    'u.s.a':'united states',\n",
    "    'u.s.a.':'united states',\n",
    "    'u.s':'united states',\n",
    "    'united state':'united states',\n",
    "    'unites states':'united states',\n",
    "    'united stated':'united states',\n",
    "    'the united states':'united states',\n",
    "    'united state of america':'united states',\n",
    "    'united stares':'united states',\n",
    "    'united statea':'united states',\n",
    "    'united status':'united states',\n",
    "    'usa tomorrow':'united states',\n",
    "    'united sates of america':'united states',\n",
    "    'united states of american':'united states',\n",
    "    'united statss':'united states',\n",
    "    'usd':'united states',\n",
    "    'united  states':'united states',\n",
    "    'united statues':'united states',\n",
    "    'unitied states':'united states',\n",
    "    'usaa':'united states',\n",
    "    'united states- puerto rico':'united states',\n",
    "    'united states is america':'united states',\n",
    "    'unitef stated':'united states',\n",
    "    'united stateds':'united states',\n",
    "    'us govt employee overseas, country withheld':'united states',\n",
    "    'united statees':'united states',\n",
    "    'uniyed states':'united states',\n",
    "    'uniyes states':'united states',\n",
    "    'us of a':'united states',\n",
    "    'u.sa':'united states',\n",
    "    'united stattes':'united states',\n",
    "    'u.s>':'united states',\n",
    "    'usa-- virgin islands':'united states',\n",
    "    'united statws':'united states',\n",
    "    'uniited states':'united states',\n",
    "    'united statesp':'united states',\n",
    "    'united states (i work from home and my clients are all over the us/canada/pr':'united states',\n",
    "    'unted states':'united states',\n",
    "    'uss':'united states',\n",
    "    'uniteed states':'united states',\n",
    "    'u. s.':'united states',\n",
    "    'united sates':'united states',\n",
    "    'unitedstates':'united states',\n",
    "    'unite states':'united states',\n",
    "    'united sttes':'united states',\n",
    "    'uniter statez':'united states',\n",
    "    'untied states':'united states',\n",
    "    'united statew':'united states',\n",
    "    'for the united states government, but posted overseas':'united states',\n",
    "    '':'united states',\n",
    "    'u. s':'united states',\n",
    "    'i.s':'united states',\n",
    "    'i.s.':'united states',\n",
    "    'isa':'united states',\n",
    "    'the us':'united states',\n",
    "    'united y':'united states',\n",
    "    'usa (company is based in a us territory, i work remote)':'united states',\n",
    "    'united states of americas':'united states',\n",
    "    'na':'united states',\n",
    "    'usab':'united states',\n",
    "    'california':'united states',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    'uk':'united kingdom',\n",
    "    'u.k.':'united kingdom',\n",
    "    'u.k.':'united kingdom',\n",
    "    'nz':'new zealand',\n",
    "    'wales':'united kingdom',\n",
    "    'england, uk':'united kingdom',\n",
    "    'england, united kingdom':'united kingdom',\n",
    "    'northern ireland':'ireland',\n",
    "    'scotland, uk':'united kingdom',\n",
    "    'uk (england)':'united kingdom',\n",
    "    'united kingdom (england)':'united kingdom',\n",
    "    'england, uk.':'united kingdom',\n",
    "    'england/uk':'united kingdom',\n",
    "    'n/a (remote from wherever i want)':'remote',\n",
    "    'austria, but i work remotely for a dutch/british company':'netherlands',\n",
    "    'panam':'panama',\n",
    "    'canada, ottawa, ontario':'canada',\n",
    "    'unites kingdom':'united kingdom',\n",
    "    'remote (philippines)':'remote',\n",
    "    'canad':'canada',\n",
    "    'company in germany. i work from pakistan.':'germany',\n",
    "    'hong konh':'hong kong',\n",
    "    'aotearoa new zealand':'new zealand',\n",
    "    'i work for a uae-based organization, though i am personally in the us.':'united arab emirates',\n",
    "    'uk, but for globally fully remote company':'remote',\n",
    "    'northern ireland, united kingdom':'united kingdom',\n",
    "    'argentina but my org is in thailand':'thailand',\n",
    "    'mxico':'mexico',\n",
    "    'uk, but for globally fully remote company':'remote',\n",
    "    'from new zealand but on projects across apac':'remote',\n",
    "\n",
    "    'ua':'ukraine',\n",
    "    'worldwide (based in us but short term trips aroudn the world)':'remote',\n",
    "    'uk, remote':'remote',\n",
    "    'can':'canada',\n",
    "    'i am located in canada but i work for a company in the us':'united states',\n",
    "    'u.a.':'ukraine',\n",
    "    'canad':'canada',\n",
    "    'uk for u.s. company':'united states',\n",
    "    'uk (northern ireland)':'united kingdom',\n",
    "    'mainland china':'china',\n",
    "    'csnada':'canada',\n",
    "    'japan, us gov position':'united states',\n",
    "    'virginia':'united states',\n",
    "    'jersey, channel islands':'channel islands',\n",
    "    'italy (south)':'italy',\n",
    "    'eritrea':'africa',\n",
    "    'canadw':'canada',\n",
    "    'international':'remote',\n",
    "    'englang':'united kingdom',\n",
    "    'nederland':'netherlands',\n",
    "    'u.k':'united kingdom',\n",
    "    'sierra leone':'africa',\n",
    "    'united kingdomk':'united kingdom',\n",
    "    'u.k. (northern england)':'united kingdom',\n",
    "    'danmark':'denmark',\n",
    "    'wales (united kingdom)':'united kingdom',\n",
    "    'somalia':'africa',\n",
    "    'from romania, but for an us based company':'united states',\n",
    "    'cote d\\'ivoire':'africa',\n",
    "    'australi':'australia',\n",
    "    'united kingdom.':'united kingdom',\n",
    "    'canda':'canada',\n",
    "    'san francisco':'united states',\n",
    "    'usat':'united states',\n",
    "    'wales (uk)':'united kingdom',\n",
    "    'australian':'australia',\n",
    "    'usa, but for foreign gov\\'t':'united states',\n",
    "    'wales, uk':'united kingdom',\n",
    "    'new zealand aotearoa':'new zealand',\n",
    "    'is':'united states',\n",
    "    'nl':'netherlands',\n",
    "    'uae':'united arab emirates',\n",
    "    'i work for an us based company but i\\'m from argentina.':'united states',\n",
    "    'united kindom':'united kingdom',\n",
    "    'australian':'australia',\n",
    "    'australian':'australia',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " }\n",
    "\n",
    "def map_country(value):\n",
    "    return country_mapping.get(value, value)\n",
    "holding_countries = holding_countries.map(map_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_countries_value_counts_after = holding_countries.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2249 united states, 16853 united states, 12504 united states, 7361 united states, 12905 united states\n",
    "# 7789 delete, uxz country - 22659 delete , y country - 1971 delete, contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                                                                    4/27/2021 11:40:54\n",
       "age                                                                                        29.5\n",
       "industry                                                          Accounting, Banking & Finance\n",
       "job title                                                             senior banking associate \n",
       "job_title_context                             Assistant branch manager, they just don't like...\n",
       "salary                                                                                    37000\n",
       "compensation                                                                            37000.0\n",
       "currency                                                                                    USD\n",
       "other_currency                                                                              NaN\n",
       "income_context                                                                              NaN\n",
       "country                                       We don't get raises, we get quarterly bonuses,...\n",
       "state                                                                             Massachusetts\n",
       "city                                                                                    Mashpee\n",
       "professional_experience_overall                                                             9.0\n",
       "professional_experience_in_specified_field                                                  3.0\n",
       "education                                                                        College degree\n",
       "gender                                                                                    Woman\n",
       "race                                                                                      White\n",
       "total_salary                                                                            74000.0\n",
       "Name: 2249, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2249]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the following code once per restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unexplainable columns\n",
    "# df.drop([7789, 22659,1971 ], axis = 0)\n",
    "\n",
    "# find columns where country was actually income context, replace income context with country \n",
    "# then replace the country with the actual country\n",
    "\n",
    "# there has to be a better way to do this rather than hardcoding the locations\n",
    "\n",
    "df.iloc[2249, df.columns.get_loc('income_context')] = df.iloc[2249]['country']\n",
    "df.iloc[16853, df.columns.get_loc('income_context')] = df.iloc[16853]['country']\n",
    "df.iloc[7361, df.columns.get_loc('income_context')] = df.iloc[7361]['country']\n",
    "df.iloc[12905, df.columns.get_loc('income_context')] = df.iloc[12905]['country']\n",
    "\n",
    "df.iloc[2249, df.columns.get_loc('country')] = 'united states'\n",
    "df.iloc[16853, df.columns.get_loc('country')] = 'united states'\n",
    "df.iloc[7361, df.columns.get_loc('country')] = 'united states'\n",
    "df.iloc[12905, df.columns.get_loc('country')] = 'united states'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the holding countries back into the country column on main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>job title</th>\n",
       "      <th>job_title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>income_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>professional_experience_overall</th>\n",
       "      <th>professional_experience_in_specified_field</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>total_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>research and instruction librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "      <td>55000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>change &amp; internal communications manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "      <td>58600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>marketing specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "      <td>34000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>program manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>accounting manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "      <td>67000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27985</th>\n",
       "      <td>10/13/2023 16:12:13</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Engineering or Manufacturing</td>\n",
       "      <td>email marketing manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "      <td>137500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27986</th>\n",
       "      <td>10/14/2023 4:54:39</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>advisor associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Asian or Asian American</td>\n",
       "      <td>77000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27987</th>\n",
       "      <td>10/16/2023 6:58:49</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Plumbing</td>\n",
       "      <td>manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ZAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>south africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27988</th>\n",
       "      <td>10/16/2023 7:07:11</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Plumbing</td>\n",
       "      <td>manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ZAR</td>\n",
       "      <td>ZAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>south africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27989</th>\n",
       "      <td>10/26/2023 8:17:05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>ibterb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>875520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Another option not listed here or prefer not t...</td>\n",
       "      <td>875520.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27990 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp   age                       industry  \\\n",
       "0       4/27/2021 11:02:10  29.5   Education (Higher Education)   \n",
       "1       4/27/2021 11:02:22  29.5              Computing or Tech   \n",
       "2       4/27/2021 11:02:38  29.5  Accounting, Banking & Finance   \n",
       "3       4/27/2021 11:02:41  29.5                     Nonprofits   \n",
       "4       4/27/2021 11:02:42  29.5  Accounting, Banking & Finance   \n",
       "...                    ...   ...                            ...   \n",
       "27985  10/13/2023 16:12:13  29.5   Engineering or Manufacturing   \n",
       "27986   10/14/2023 4:54:39  29.5  Accounting, Banking & Finance   \n",
       "27987   10/16/2023 6:58:49  65.0                       Plumbing   \n",
       "27988   10/16/2023 7:07:11  65.0                       Plumbing   \n",
       "27989   10/26/2023 8:17:05  21.0              Computing or Tech   \n",
       "\n",
       "                                      job title job_title_context  salary  \\\n",
       "0            research and instruction librarian               NaN   55000   \n",
       "1      change & internal communications manager               NaN   54600   \n",
       "2                          marketing specialist               NaN   34000   \n",
       "3                               program manager               NaN   62000   \n",
       "4                            accounting manager               NaN   60000   \n",
       "...                                         ...               ...     ...   \n",
       "27985                   email marketing manager               NaN  125000   \n",
       "27986                         advisor associate               NaN   72000   \n",
       "27987                                   manager               NaN   30000   \n",
       "27988                                   manager               NaN   30000   \n",
       "27989                                   ibterb                NaN  875520   \n",
       "\n",
       "       compensation currency other_currency income_context         country  \\\n",
       "0               0.0      USD            NaN            NaN   united states   \n",
       "1            4000.0      GBP            NaN            NaN  united kingdom   \n",
       "2               0.0      USD            NaN            NaN   united states   \n",
       "3            3000.0      USD            NaN            NaN   united states   \n",
       "4            7000.0      USD            NaN            NaN   united states   \n",
       "...             ...      ...            ...            ...             ...   \n",
       "27985       12500.0      USD            NaN            NaN   united states   \n",
       "27986        5000.0      USD            NaN            NaN   united states   \n",
       "27987       10000.0      ZAR            NaN            NaN    south africa   \n",
       "27988       10000.0      ZAR            ZAR            NaN    south africa   \n",
       "27989           0.0      USD            NaN            NaN         nigeria   \n",
       "\n",
       "                state          city  professional_experience_overall  \\\n",
       "0       Massachusetts        Boston                              6.0   \n",
       "1                 NaN     Cambridge                              9.0   \n",
       "2           Tennessee   Chattanooga                              3.0   \n",
       "3           Wisconsin     Milwaukee                              9.0   \n",
       "4      South Carolina    Greenville                              9.0   \n",
       "...               ...           ...                              ...   \n",
       "27985        Illinois       Chicago                              6.0   \n",
       "27986          Nevada     Las Vegas                              3.0   \n",
       "27987             NaN  Johannesburg                             41.0   \n",
       "27988             NaN  Johannesburg                             41.0   \n",
       "27989             NaN         Lagos                              3.0   \n",
       "\n",
       "       professional_experience_in_specified_field        education  \\\n",
       "0                                             6.0  Master's degree   \n",
       "1                                             6.0   College degree   \n",
       "2                                             3.0   College degree   \n",
       "3                                             6.0   College degree   \n",
       "4                                             6.0   College degree   \n",
       "...                                           ...              ...   \n",
       "27985                                         3.0   College degree   \n",
       "27986                                         3.0   College degree   \n",
       "27987                                        41.0      High School   \n",
       "27988                                        41.0              NaN   \n",
       "27989                                         3.0   College degree   \n",
       "\n",
       "           gender                                               race  \\\n",
       "0           Woman                                              White   \n",
       "1      Non-binary                                              White   \n",
       "2           Woman                                              White   \n",
       "3           Woman                                              White   \n",
       "4           Woman                                              White   \n",
       "...           ...                                                ...   \n",
       "27985       Woman                                              White   \n",
       "27986         Man                            Asian or Asian American   \n",
       "27987         Man                                              White   \n",
       "27988         Man                                              White   \n",
       "27989         Man  Another option not listed here or prefer not t...   \n",
       "\n",
       "       total_salary  \n",
       "0           55000.0  \n",
       "1           58600.0  \n",
       "2           34000.0  \n",
       "3           65000.0  \n",
       "4           67000.0  \n",
       "...             ...  \n",
       "27985      137500.0  \n",
       "27986       77000.0  \n",
       "27987       40000.0  \n",
       "27988       40000.0  \n",
       "27989      875520.0  \n",
       "\n",
       "[27990 rows x 19 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'] = holding_countries\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_to_state_mapping = {\n",
    "    'San Nicols de los Arroyos': 'Buenos Aires',\n",
    "    'Oaxaca de Juarez (home). Company I work for is based in Los ngeles': 'Oaxaca',\n",
    "    'Greater NYC Metro': 'New York',\n",
    "    'Chicago, IL (but I work remotely)': 'Illinois',\n",
    "    'Norristown, PA': 'Pennsylvania',\n",
    "    'US govt employee overseas, country withheld': 'Overseas',\n",
    "    'Several': 'Several',  \n",
    "    'Minneapolis': 'Minnesota',\n",
    "    'Midwest region': 'Midwest',  \n",
    "    'Boston': 'Massachusetts',\n",
    "    'Detroit': 'Michigan',\n",
    "    'NaN': np.nan,  \n",
    "    'Remote': np.nan, \n",
    "    'Major metropolitan area': np.nan,  \n",
    "    'Le Center': 'Minnesota',\n",
    "    'Bennington': 'Vermont',\n",
    "    'Aguadilla': 'Puerto Rico',\n",
    "    'Redding': 'California',\n",
    "    'National-Remote': 'National',  \n",
    "    'Dallas': 'Texas',\n",
    "    'New York': 'New York',\n",
    "    'Wilmington': 'Delaware',\n",
    "    'Im remote but my company is based in Massachusetts': 'Massachusetts',\n",
    "    'Not answering': np.nan,  \n",
    "    'Denver': 'Colorado',\n",
    "    'Nyc': 'New York',\n",
    "    'East Coast USA': np.nan,  \n",
    "    'Prefer not to disclose': np.nan,  \n",
    "    'Springfield': 'Illinois',\n",
    "    'Fully remote company based out of CA': 'California',\n",
    "    'Philadelphia - can you help me?': 'Pennsylvania',\n",
    "    'NaN': np.nan  \n",
    "}\n",
    "df['state'] = df['city'].map(city_to_state_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_cities = df[['state','city']]\n",
    "holding_cities_value_counts = df['city'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_jobs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['industry'] = df['industry'].str.lower()\n",
    "holding_jobs['industry'] = df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you downloaded a csv file containing the us city information \n",
    "# you then created a dataframe containing the null values in state column and there had to be a value in the city \n",
    "# column, and you only selected us cities.\n",
    "# then you i think had to merge the dataframes on the city so you had the state they belonged to on a new column, afterwards\n",
    "# you then merged that onto the dataframe, but i dont think that worked \n",
    "\n",
    "\n",
    "\n",
    "# if city contains remote, remotely , state should be remote\n",
    "# if city contains rural, area, whatever that needs to be removed \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# city mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i dont think you ever added a way to make the city column be the state colum if the city colum \n",
    "# matches the state list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_city_use = ('north','east','south','west','north','east','south','west','northern','eastern','southern','western','rural','metro','area','suburb','suburbs','state','greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing common words\n",
    "df['city'] = df.apply(lambda row: ' '.join([word for word in row['city'].split() if word.lower() not in common_city_use]) if isinstance(row['city'], str) else row['city'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city'] = df.apply(lambda row: row['city'].replace('.','') if isinstance(row['city'],str) and '.' in row['city'] else row['city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city'] = df.apply(lambda row: row['city'].replace(',','') if isinstance(row['city'],str) and ',' in row['city'] else row['city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\3077268215.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_city_mapping.loc[:, 'city'] = df_city_mapping['city'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\3077268215.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_city_mapping.loc[:, 'state_name'] = df_city_mapping['state_name'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\3077268215.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_city_mapping_abbrev.loc[:, 'state_id'] = df_city_mapping_abbrev['state_id'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\3077268215.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_city_mapping_abbrev.loc[:, 'state_name'] = df_city_mapping_abbrev['state_name'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# creates 2 seperate dataframes from us city mapping information. one contains city and state name and the other \n",
    "# contains city and state id ( 2 char ) \n",
    "# https://simplemaps.com/data/us-cities \n",
    "us_city_information = pd.read_csv('uscities.csv')\n",
    "us_city_information.drop_duplicates(subset=['city'],keep='first',inplace=True)\n",
    "df_city_mapping = us_city_information[['city','state_name']]\n",
    "df_city_mapping.loc[:, 'city'] = df_city_mapping['city'].str.lower()\n",
    "df_city_mapping.loc[:, 'state_name'] = df_city_mapping['state_name'].str.lower()\n",
    "#mapping for abbrevations\n",
    "df_city_mapping_abbrev = us_city_information[['state_id','state_name']]\n",
    "df_city_mapping_abbrev.loc[:, 'state_id'] = df_city_mapping_abbrev['state_id'].str.lower()\n",
    "df_city_mapping_abbrev.loc[:, 'state_name'] = df_city_mapping_abbrev['state_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1028388201.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_city_mapping_abbrev.drop_duplicates(keep='first',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_city_mapping_abbrev.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is creating a copy of the original df only containign what is needed, then it will only select\n",
    "# where country is == us. \n",
    "\n",
    "# im thinking this is incorrect because you want to keep working with the whole set of data  because then it makes \n",
    "# the merging process much easier when the table sare the same lengths. \n",
    "\n",
    "# the idea is to do the following work onthe main dataframe or do it the same way but keep the size the same as the \n",
    "# original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1004209631.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities.loc[:, 'city'] = df_working_cities['city'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1004209631.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_working_cities.loc[:, 'city'] = df_working_cities['city'].str.replace('.', '')\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1004209631.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities.loc[:, 'city'] = df_working_cities['city'].str.replace('.', '')\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1004209631.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities.loc[:, 'city'] = df_working_cities['city'].str.strip()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1004209631.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities.loc[:, 'state'] = df_working_cities['state'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1004209631.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities.loc[:, 'state_id'] = df_working_cities['city'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "df_working_cities = df[['country', 'state', 'city']]\n",
    "df_working_cities.loc[:, 'city'] = df_working_cities['city'].str.lower()\n",
    "df_working_cities.loc[:, 'city'] = df_working_cities['city'].str.replace('.', '')\n",
    "df_working_cities.loc[:, 'city'] = df_working_cities['city'].str.strip()\n",
    "df_working_cities.loc[:, 'state'] = df_working_cities['state'].str.lower()\n",
    "df_working_cities.loc[:, 'state_id'] = df_working_cities['city'].str.lower()\n",
    "df_working_cities = df_working_cities.loc[df_working_cities['country'] == 'united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\250986789.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities_test['city'] = df_working_cities_test['city'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\250986789.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_working_cities_test['city'] = df_working_cities_test['city'].str.replace('.', '')\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\250986789.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities_test['city'] = df_working_cities_test['city'].str.replace('.', '')\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\250986789.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities_test['city'] = df_working_cities_test['city'].str.strip()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\250986789.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities_test['state'] = df_working_cities_test['state'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\250986789.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_working_cities_test['state_id'] = df_working_cities_test['city'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "df_working_cities_test = df[['country', 'state', 'city']]\n",
    "df_working_cities_test['city'] = df_working_cities_test['city'].str.lower()\n",
    "df_working_cities_test['city'] = df_working_cities_test['city'].str.replace('.', '')\n",
    "df_working_cities_test['city'] = df_working_cities_test['city'].str.strip()\n",
    "df_working_cities_test['state'] = df_working_cities_test['state'].str.lower()\n",
    "df_working_cities_test['state_id'] = df_working_cities_test['city'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_working_cities_test['city'] = df_working_cities_test.apply(lambda row: 'san francisco' if isinstance(row['city'],str) and row['city']=='san francisco bay' else row['city'],axis=1 )\n",
    "# df_working_cities_test['city'] = df_working_cities_test.apply(lambda row: 'chicago' if isinstance(row['city'],str) and row['city']=='chicagoland' else row['city'],axis=1 )\n",
    "# df_working_cities_test['city'] = df_working_cities_test.apply(lambda row: 'minneapolis' if isinstance(row['city'],str) and row['city']=='minneapolis-st paul' or 'minneapolis/st paul'  else row['city'],axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_test = pd.merge(df_working_cities_test, df_city_mapping, on='city',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the following code is wiping the information in the state_name column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge_test['state'] = df_merge_test['state_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_test['state'] =df_merge_test.apply(lambda row: row['state_name'] if row['country'] == 'united states' \n",
    "                                                                            and pd.isna(row['state']) \n",
    "                                                                            and ~pd.isna(row['state_name'])\n",
    "                                                                            else row['state'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_test['city'] = df_merge_test['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the working dataframe with the city mapping containing city and state on the cities\n",
    "df_merge = pd.merge(df_working_cities, df_city_mapping, on='city',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing nan values in state (if there already is one why replace) with the new state that was merged on \n",
    "df_merge['state'].fillna(df_merge['state_name'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating id column to hold state abbrevation for  mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating state id column containing the 2 characters, if the second split element is 2 len and 2 total splits and not nan\n",
    "df_merge_test['state_id'] = df_merge_test['city'].apply(lambda x: x.split()[1] if isinstance(x, str) and len(x.split()) == 2 and len(x.split()[1])==2 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating state id column for 2nd index ie st louis mo , need to place mo in column as well \n",
    "df_merge_test['state_id'] = df_merge_test.apply(lambda row: row['city'].split()[2] if isinstance(row['city'], str) and len(row['city'].split()) == 3 and len(row['city'].split()[2])==2 else row['state_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_test['state_id'] = df_merge_test.apply(lambda row: row['state_id'].lower() if isinstance(row['state_id'],str) else row['state_id'],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above should be performing this function. got an error here when adding in the san fran / chicagoland remapping \n",
    "#df_merge_test['state_id'] = df_merge_test['state_id'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_test['state_name'] =  df_merge_test['state_name'].str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging working dataframe and the mapping dataframe containing id and state on state_id\n",
    "df_merge_test = pd.merge(df_merge_test, df_city_mapping_abbrev, on='state_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge_test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youve got the state y , now you need to place it in the state column if it is nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youve got state names from abbrev, now you need to find a way to place it into the sate column. the following seems to \n",
    "# brick the code once again, but this is where you are leaving off today. 12/20\n",
    "# first \n",
    "#df_merge_test['state'] = df_merge_test.apply(lambda row: row['state_name_y'] if isinstance(row['state_name_y'],str) and row['state'] == np.nan and row['country']=='united states' else row['state'],axis=1)\n",
    "# testing\n",
    "df_merge_test['state'] = df_merge_test.apply(lambda row: row['state_name_y'] if isinstance(row['state_name_y'],str) and pd.isna(row['state']) and row['country']=='united states' else row['state'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing state with new state name from merge if its nan\n",
    "# this one taken out\n",
    "#df_merge_test['state'].fillna(df_merge_test['state_name_y'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge_test['state'] = df_merge_test.apply(lambda row: row['state_name_y'] if isinstance(row['state_name_y'],str) and row['state'] == np.nan() else row['state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_test['city'] = df_merge_test['city'].str.lower()\n",
    "df_merge_test['state'] = df_merge_test['state'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where state is nan\n",
    "# split city, if city split == 2 len then split[0] is city \n",
    "# need to merge back into main dataframe frist, cayse the only thing tieing the new one to base one is the city\n",
    "# instead of using merge dataframe, you might be able to perform them on the main dataframe, you just have to filter it \n",
    "# making sure your only performing process where country is usa \n",
    "#df_merge.dropna(subset='state', inplace=True)\n",
    "# you are not droppign columns yet cause it messes up when you go to merge dataframe back together\n",
    "# you can do some city cleaning to get information from toher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city'] = df['city'].str.lower() \n",
    "df['state'] = df['state'].str.lower() \n",
    "df['city'] = df['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge_test.drop_duplicates(subset=['city'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_essential = df_merge_test[['state','city']].drop_duplicates(keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_essential.dropna(subset=['state'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe from working dataframe to merge back to main df, \n",
    "df = pd.merge(df, df_merge_essential, on='city',how='left')\n",
    "#df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing code\n",
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where you were working last 1/3/24, you are lazily replacing the state values where it had merged - \n",
    "# but instead you only want to replace the values where the country is united states along with whatever else\n",
    "# however the following code ends up replacing all values as nan\n",
    "# you need to check and make sure state_y is not nan value either?   \n",
    "df['state_x'] = df.apply(lambda row: row['state_y'] if pd.isna(row['state_x']) and pd.notnull(row['state_y']) and (row['country']=='united states') else row['state_x'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you were going to try the below method to replace the original values with ones from merge, but you realised you had \n",
    "# a mistake of capitalizing united states when the its lowercase\n",
    "# df1['state_x'] = np.where(\n",
    "#     (df1['country'] == 'United States') & pd.isna(df1['state_x']) & pd.notnull(df1['state_y']),\n",
    "#     df1['state_y'],\n",
    "#     df1['state_x']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing old state with new states\n",
    "# df['state_x'].fillna(df['state_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'state_x':'state'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('state_y',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# canada part of states and cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do what you did above with canada data! \n",
    "# getting map data and lower \n",
    "df_canada_city_mapping = pd.read_csv('canadacities.csv')\n",
    "df_canada_city_mapping.drop_duplicates(subset=['city'],keep='first',inplace=True)\n",
    "df_canada_city_mapping['city'] = df_canada_city_mapping['city'].str.lower() \n",
    "df_canada_city_mapping['province_name'] = df_canada_city_mapping['province_name'].str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'city_ascii', 'province_id', 'province_name', 'lat', 'lng',\n",
       "       'population', 'density', 'timezone', 'ranking', 'postal', 'id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_canada_city_mapping.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using city and provice name \n",
    "df_canada_city_mapping_work = df_canada_city_mapping[['city','province_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe where country is canada\n",
    "df_canada = df.loc[df['country']=='canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\2513260064.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_canada['city'] = df_canada['city'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "# stripping city\n",
    "df_canada['city'] = df_canada['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\3015519422.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_canada['city'].replace('',\"'\",inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_canada['city'].replace('',\"'\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\2486081859.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_canada['city'] = df_canada['city'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "df_canada['city'] = df_canada['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you go to merge it back together the city has white strips so its not joining all the columns possible\n",
    "df['city'] = df['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada = pd.merge(df_canada, df_canada_city_mapping_work, on='city',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada['state'] = df_merge_canada['state'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'] = df['state'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada['state'] = df_merge_canada['province_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you need to clean up the rest of the df_merge_canada df where they put in providence in the state column \n",
    "# it is okay to drop state_y from main dataframe now as well. \n",
    "# \n",
    "\n",
    "\n",
    "# you can split the city column and grab the second entry, then you can see if it matches either the provendince full name\n",
    "# or the abbrevated version. if it does , fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada_split = df_merge_canada[['city','state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_state = df_merge_canada['state'].unique()\n",
    "# you are creating a list to store each prov then seeing if the split below contains it, then replacing it in state\n",
    "# you are wondering what you are going to replace if there isnt anything you want ot store \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# canada city replacing value in state if city is equal to a city value defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge_canada_split['state'] = df_merge_canada_split['city'].apply(lambda x: x.split()[1] if isinstance(x,str) and pd.isna(x['state']) and isinstance(x['city'],str)and x.split()[1] in canada_state else x['state'])\n",
    "df_merge_canada['state'] = df_merge_canada.apply(\n",
    "    lambda row: row['city'].split()[1] if pd.isna(row['state']) and isinstance(row['city'], str) and len(row['city'].split()) > 1 and row['city'].split()[1] in canada_state else row['state'], \n",
    "    axis=1\n",
    ")\n",
    "df_merge_canada['state'] = df_merge_canada.apply(lambda row: row['city'].split()[0] if pd.isna(row['state']) and isinstance(row['city'], str) and row['city'] in canada_state else row['state'], \n",
    "    axis=1\n",
    ")\n",
    "# df_merge['state_id'] = df_merge['city'].apply(lambda x: x.split()[1] if isinstance(x, str) and len(x.split()) == 2 and len(x.split()[1])==2 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\2060402295.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  canada_state_abbrev['province_id'] = canada_state_abbrev['province_id'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\2060402295.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  canada_state_abbrev.drop_duplicates(inplace=True, keep='first')\n"
     ]
    }
   ],
   "source": [
    "canada_state_abbrev = df_canada_city_mapping[['province_id', 'province_name']]\n",
    "canada_state_abbrev['province_id'] = canada_state_abbrev['province_id'].str.lower()\n",
    "canada_state_abbrev.drop_duplicates(inplace=True, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes this wants to be changed to _x\n",
    "df_merge_canada['state'] = df_merge_canada.apply(\n",
    "    lambda row: row['province_name'] if pd.isna(row['state']) and isinstance(row['city'], str) else row['state'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge_canada['state'] = df_merge_canada.apply(\n",
    "#     lambda row: row['province_name_x'] if pd.isna(row['state']) and isinstance(row['city'], str) and len(row['city'].split()) > 1 and row['city'].split()[1] in canada_state_abbrev else row['state'],\n",
    "#     axis=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapping_canada_abbrev = dict(zip(canada_state_abbrev['province_id'],canada_state_abbrev['province_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge_canada_split['state'] = df_merge_canada_split['city'].apply(\n",
    "#     lambda x: state_mapping_canada_abbrev.get(x.split(' ')[-1]) if isinstance(x, str) and pd.notna(x) else df_merge_canada_split['state']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge_canada_split['state'] = df_merge_canada_split.apply(\n",
    "#     lambda row: state_mapping_canada_abbrev.get(row['city'].split(' ')[-1]) if isinstance(row['city'], str) and pd.notna(row['city']) and pd.notna(row['state']) else row['state'],\n",
    "#     axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada['province_id'] = df_merge_canada['city'].apply(lambda row:row.split()[1] if  isinstance(row, str) and len(row.split()) > 1 and row.split()[1] != np.nan and len(row.split()[1]) == 2 else np.nan) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what you were wokring on last, the follwoing code does not work. you are trying to place the 2 digit bc from city into \n",
    "# province id column so you can display it as british columbia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada['province_id'] = np.where(\n",
    "    (df_merge_canada['city'].apply(lambda x: isinstance(x, str) and len(x) == 2) & pd.notna(df_merge_canada['state'])),\n",
    "    df_merge_canada['city'],\n",
    "    df_merge_canada['province_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_city(row):\n",
    "#     city = row['city']\n",
    "#     province_id = row['province_id']\n",
    "\n",
    "#     if isinstance(city, str) and pd.isna(province_id) and len(city.split()) > 1 and city.split()[0] != np.nan and len(city.split()[0]) == 2:\n",
    "#         return city.split()[0]\n",
    "#     else:\n",
    "#         return province_id\n",
    "\n",
    "# df_merge_canada['province_id'] = df_merge_canada.apply(process_city, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada = pd.merge(df_merge_canada,canada_state_abbrev, on='province_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merge_canada['state']= df_merge_canada.apply(lambda row: row['province_name_y'] if pd.isna(row['state']) else row['state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you are still getting citys that shouldve been converted such as bc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada['state'] = df_merge_canada.apply(\n",
    "    lambda row: row['province_name'] if pd.notna(row['state']) \n",
    "                                     and isinstance(row['city'], str) \n",
    "                                     and len(row['city'].split()) > 1 \n",
    "                                     and row['city'].split()[1] \n",
    "                                     in canada_state_abbrev else row['state']\n",
    "                                     ,axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_canada_merging_final = df_merge_canada[['city','state','country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready to join working canada dataframe back to the original dataframe, merge state on city then replace state if country = canada\n",
    "# and state = nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the reason youw ere getting us states in canada was because when you replaced states in original dataframe with what matched, \n",
    "# you didnt specify that it should only be where country = united_states \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because you want to merge the dataframe when you take slices where country is what you want , you are going to run into issues at \n",
    "# the end because there are ctities that are going to exist in mulitple countrys SO when you go to join on city you are going to run \n",
    "# into issues wehre you get state illios for country canada\n",
    "\n",
    "# also you could join the the state And country on city so then you could only reaplce city if country and county x equal eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_canada_merging_final, on='city',how='left')\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'age', 'industry', 'job title', 'job_title_context',\n",
       "       'salary', 'compensation', 'currency', 'other_currency',\n",
       "       'income_context', 'country_x', 'state_x', 'city',\n",
       "       'professional_experience_overall',\n",
       "       'professional_experience_in_specified_field', 'education', 'gender',\n",
       "       'race', 'total_salary', 'state_y', 'country_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "         ... \n",
       "333418    NaN\n",
       "333419    NaN\n",
       "333420    NaN\n",
       "333421    NaN\n",
       "333422    NaN\n",
       "Name: state_y, Length: 28060, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['state_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_canada['state'] = df_merge_canada.apply(\n",
    "    lambda row: row['province_name'] if pd.notna(row['state']) and isinstance(row['city'], str) and len(row['city'].split()) > 1 and row['city'].split()[1] in canada_state_abbrev else row['state'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'state_y' in df.columns:\n",
    "#     df['state_x'] = df.apply(lambda row: row['state_y'] if\n",
    "#                                     isinstance(row['state_y'], str) and \n",
    "#                                     len(row['state_y']) > 1 and \n",
    "#                                     row['country_x'] == 'canada' else \n",
    "#                                     row['state_x'], axis=1)\n",
    "# else:\n",
    "#     print(\"Column 'state_y' not found in DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['state_y', 'country_y'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.rename(columns={'state_x':'state'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i think wehn you left off you were workin on how twould you clean up the rest of the nan state in df_)canada _merge \n",
    "# you need to merge this back ont o the main dataframe, then you should be able to drop all rows where state is nan \n",
    "# you could do some value count work here to determine how many are having missing state and if its worthwhile taking a close rlook into\n",
    "# actually you need to repeat the above process for the uk THEN you are able to start dropping rows. you could drop rwos beforehand\n",
    "# if there was a way to only select rows where country = cananda AND state = nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in df where country is canada we need to replace state x with state y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe to test how to place the state y canada correct state into state x state column holding all states\n",
    "df_test = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placing state y into state x if country is canada\n",
    "df_test.loc[df_test['country_x'] == 'canada', 'state_x'] = df_test[df_test['country_x'] == 'canada']['state_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it worked, so now you can do it on main dataframe\n",
    "# you can also now drop the columns at the end of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['country_x'] == 'canada', 'state_x'] = df[df['country_x'] == 'canada']['state_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the joined columns \n",
    "df.drop(columns=['state_y','country_y'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'age', 'industry', 'job title', 'job_title_context',\n",
       "       'salary', 'compensation', 'currency', 'other_currency',\n",
       "       'income_context', 'country_x', 'state_x', 'city',\n",
       "       'professional_experience_overall',\n",
       "       'professional_experience_in_specified_field', 'education', 'gender',\n",
       "       'race', 'total_salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns from _x \n",
    "df.rename(columns={'country_x':'country','state_x':'state'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i think it would be a good idea to put state as nan if country is not united states or canada\n",
    "df_test['state'] = df_test.apply(lambda row: np.nan if row['country'] not in ['canada','united states'] else row['state'],axis=1)                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test worked, now on main dataframe\n",
    "df['state'] = df.apply(lambda row: np.nan if row['country'] not in ['canada','united states'] else row['state'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i think you want to go through and deal with state indicators within the city column. The state name or abbrevation should\n",
    "# be removed from the city column in every row. \n",
    "# after taking a look and seeing whats going on , you still need to work on the us cities as you did it quite lazily the first time\n",
    "# around. you need to make it so things like new york, ny have a state of new york. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it appears you are exparimenting with trying to remove the state from city column if it so exists in effort to clean\n",
    "# data before visualization \n",
    "\n",
    "# you should also then try to remove abbrevation as there are a lot more of them. Create a list of them using unique method\n",
    "# on the dataframe created on the csv file but on the city ascii or whatever it is as a series. Then if it matches the \n",
    "# df['city'].split()[1] or however you do it, replace it with ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['city'] = df_test.apply(lambda row: row['city'].replace(row['state'],'') if pd.notna(row['state']) and row['state'] in row['city'] and row['city'] != np.nan else row['city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe with industries you dont need to do anything to it cause it looks like they were given choices. \n",
    "# so next i think you would want to delete all rows that are ranked above 100 in value counts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industries = df[['industry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08333333333333333"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# online solution \n",
    "\n",
    "# value_counts_result = df['column_name'].value_counts()\n",
    "\n",
    "# # Select the top 100 rows\n",
    "# top_100_rows = value_counts_result.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industries = df_industries.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_industries.rename({'index':'field','industry':'count'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could maybe take the top 100 from industry, or you could try to rename columns so you search the now 'index' \n",
    "# for computing or hr or whatever and see if there are ones you could rename. ie service = retail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_title = df['job title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_title = df_job_title.reset_index().rename(columns={'job title': 'count', 'index': 'title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['united states', 'united kingdom', 'canada', 'scotland',\n",
       "       'the netherlands', 'australia', 'spain', 'england', 'finland',\n",
       "       'france', 'germany', 'ireland', 'india', 'argentina',\n",
       "       'great britain', 'denmark', 'netherlands', 'switzerland',\n",
       "       'bermuda', 'malaysia', 'mexico', 'south africa', 'belgium',\n",
       "       'sweden', 'hong kong', 'kuwait', 'norway', 'sri lanka',\n",
       "       'contracts',\n",
       "       \"we don't get raises, we get quarterly bonuses, but they periodically asses income in the area you work, so i got a raise because a 3rd party assessment showed i was paid too little for the area we were located\",\n",
       "       'greece', 'japan', 'britain', 'austria', 'brazil', 'global',\n",
       "       'remote', 'hungary', 'luxembourg', 'colombia', 'new zealand',\n",
       "       'trinidad and tobago', 'cayman islands', 'ukraine',\n",
       "       'czech republic', 'czechia', 'latvia', 'puerto rico', 'rwanda',\n",
       "       'united arab emirates', 'bangladesh', 'romania',\n",
       "       'currently finance', 'serbia', 'philippines', 'russia', 'poland',\n",
       "       'uxz', 'turkey', 'canada and usa', 'catalonia',\n",
       "       '$2,175.84/year is deducted for benefits', 'italy',\n",
       "       'channel islands', 'china', 'afghanistan', 'israel', 'hartford',\n",
       "       'taiwan', 'cambodia', 'vietnam', 'singapore', 'south korea',\n",
       "       'thailand', 'lithuania', 'africa', 'indonesia', 'cuba', 'slovenia',\n",
       "       'england, gb', 'slovakia', 'portugal',\n",
       "       'bonus based on meeting yearly goals set w/ my supervisor',\n",
       "       'the bahamas',\n",
       "       \"i earn commission on sales. if i meet quota, i'm guaranteed another 16k min. last year i earned an additional 27k. it's not uncommon for people in my space to earn 100k+ after commission.\",\n",
       "       'costa rica', 'chile', 'qatar', 'nigeria', 'panama',\n",
       "       'i was brought in on this salary to help with the ehr and very quickly was promoted to current position but compensation was not altered.',\n",
       "       'congo', 'uruguay', 'pakistan', 'brasil', 'uganda', 'malta',\n",
       "       'saudi arabia', 'bulgaria', 'estonia', 'morocco', 'ecuador',\n",
       "       'zimbabwe', 'ghana', 'luxemburg', 'croatia', 'y', 'isle of man',\n",
       "       'europe', 'jamaica', 'kenya', 'jordan', 'policy', 'cyprus',\n",
       "       'liechtenstein', 'bosnia and herzegovina'], dtype=object)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'the' needs to be removed from netherland entries containing it  X\n",
    "# country with britin needs to be great britain\n",
    "# luxemburg spelling all messed up \n",
    "# country being europe needs to be dropped\n",
    "# brazil entry spelled with s instead of z\n",
    "\n",
    "# california has multiple listings for same city ie sf, san franciso, and san franciso bay area - map them ?\n",
    "# map them out like you did with countries in the beginning\n",
    "\n",
    "# you could also remove east , eastern, from the cities to get more complete rows\n",
    "\n",
    "# kind of avoiding the fact you need a way to just use the top 100 value count of job title or industry , whichever\n",
    "# was the one that had higher value counts. \n",
    "\n",
    "# once you cleat the above you are going to be able to start building a dashboard. Once you have everything completed\n",
    "# you could send piatz the following data transformation and the finished dashboard along with the resume\n",
    "\n",
    "# and then also you could do your new github profile to be more professional name \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# big idea to convert salary amounts all into usd , or at least the euro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['country'] = df_clean.apply(lambda row: row['country'].replace('the','') if row['country']=='the netherlands' else row['country'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\3805101410.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_abbrev_clean['state_id'] = df_abbrev_clean['state_id'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\3805101410.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_abbrev_clean['state_name'] = df_abbrev_clean['state_name'].str.lower()\n",
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\3805101410.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_abbrev_clean.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_abbrev_clean = us_city_information[['state_id','state_name']]\n",
    "df_abbrev_clean['state_id'] = df_abbrev_clean['state_id'].str.lower() \n",
    "df_abbrev_clean['state_name'] = df_abbrev_clean['state_name'].str.lower() \n",
    "df_abbrev_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abbrev_series = df_abbrev_clean['state_id']\n",
    "df_abbrev_list = df_abbrev_series.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first solution, for some reason this didnt work but the following does \n",
    "# df_clean['city'] = df_clean.apply(lambda row: row['city'].replace(row['city'].split()[1], '') \n",
    "#                                 if isinstance(row['city'],str)\n",
    "#                                 and isinstance(row['city'].split()[1],str)\n",
    "#                                 and len(row['city']).split()[1] > 1\n",
    "#                                 and row['city'].split()[1] in df_abbrev_list\n",
    "#                                 else row['state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code takes the abbrevations used originally to get the state column, and removes them if they match\n",
    "# the list of state abbrevations. \n",
    "\n",
    "# you need to do the following for the 2nd split for st louis mo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['city'] = df_clean.apply(lambda row: str(row['city']).replace(str(row['city']).split()[1], '') \n",
    "                                if isinstance(row['city'], str)\n",
    "                                and len(str(row['city']).split()) > 1\n",
    "                                and isinstance(str(row['city']).split()[1], str)\n",
    "                                and str(row['city']).split()[1] in df_abbrev_list\n",
    "                                else row['city'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['state'] = df_clean.apply(lambda row: row['state'].split()[1].replace() if row['country']=='the netherlands' else row['country'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to remove eastern, west, etc from city column \n",
    "# then you could rerun mapping to see if there are more matches for state\n",
    "\n",
    "# 2101 rows where state = nan before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.value_counts of                   timestamp   age                       industry  \\\n",
       "480      4/27/2021 11:03:55  39.5   education (higher education)   \n",
       "1750     4/27/2021 11:04:34  29.5                     nonprofits   \n",
       "1758     4/27/2021 11:04:41  39.5              computing or tech   \n",
       "1759     4/27/2021 11:04:43  39.5                     nonprofits   \n",
       "1764     4/27/2021 11:04:50  39.5   education (higher education)   \n",
       "...                     ...   ...                            ...   \n",
       "331708  12/11/2022 10:08:24  29.5                    health care   \n",
       "332165   1/29/2023 14:26:21  39.5              computing or tech   \n",
       "333066    3/6/2023 18:16:19  29.5              behavioral health   \n",
       "333327   8/21/2023 22:47:22  18.0  accounting, banking & finance   \n",
       "333411    9/25/2023 9:20:50  21.0  accounting, banking & finance   \n",
       "\n",
       "                                             job title  \\\n",
       "480                                 senior irb analyst   \n",
       "1750    manager, natural climate solutions development   \n",
       "1758                                       tech writer   \n",
       "1759                             supervisory archivist   \n",
       "1764                     special collections cataloger   \n",
       "...                                                ...   \n",
       "331708                                      pharmacist   \n",
       "332165                             master data analyst   \n",
       "333066                         mental health therapist   \n",
       "333327                           mcdonalds crew member   \n",
       "333411                                 program analyst   \n",
       "\n",
       "                                        job_title_context  salary  \\\n",
       "480     State university, higher ed research adminstra...   68000   \n",
       "1750    This is NOT a non-profit development/fundraisi...   84000   \n",
       "1758                                                  NaN   88000   \n",
       "1759                              at a historical society   71000   \n",
       "1764                                 Tenure-track faculty   65000   \n",
       "...                                                   ...     ...   \n",
       "331708                                                NaN  151257   \n",
       "332165  Create and maintain data for all materials (pr...   57000   \n",
       "333066                                                NaN   52416   \n",
       "333327                                                NaN   40000   \n",
       "333411                                     Data Analytics   70000   \n",
       "\n",
       "        compensation currency other_currency income_context        country  \\\n",
       "480              0.0      USD            NaN            NaN  united states   \n",
       "1750          8400.0      USD            NaN            NaN  united states   \n",
       "1758             0.0      USD            NaN            NaN  united states   \n",
       "1759             0.0      USD            NaN            NaN  united states   \n",
       "1764             0.0      USD            NaN            NaN  united states   \n",
       "...              ...      ...            ...            ...            ...   \n",
       "331708        9075.0      USD            NaN            NaN  united states   \n",
       "332165           0.0      USD            NaN            NaN  united states   \n",
       "333066           0.0      USD            NaN            NaN  united states   \n",
       "333327           0.0      USD            NaN            NaN  united states   \n",
       "333411        5000.0      USD            NaN            NaN  united states   \n",
       "\n",
       "       state                        city  professional_experience_overall  \\\n",
       "480      NaN           research triangle                              6.0   \n",
       "1750     NaN        district of columbia                              6.0   \n",
       "1758     NaN        prefer not to answer                             15.5   \n",
       "1759     NaN              nyc (remotely)                             15.5   \n",
       "1764     NaN                       -----                             15.5   \n",
       "...      ...                         ...                              ...   \n",
       "331708   NaN                    colorado                              6.0   \n",
       "332165   NaN  danvers  (north of boston)                             15.5   \n",
       "333066   NaN                spotsylvania                              3.0   \n",
       "333327   NaN                         NaN                              1.0   \n",
       "333411   NaN                     stlouis                              1.0   \n",
       "\n",
       "        professional_experience_in_specified_field  \\\n",
       "480                                            3.0   \n",
       "1750                                           6.0   \n",
       "1758                                           9.0   \n",
       "1759                                           9.0   \n",
       "1764                                          15.5   \n",
       "...                                            ...   \n",
       "331708                                         9.0   \n",
       "332165                                        15.5   \n",
       "333066                                         3.0   \n",
       "333327                                         1.0   \n",
       "333411                                         1.0   \n",
       "\n",
       "                                 education gender  \\\n",
       "480                        Master's degree  Woman   \n",
       "1750                       Master's degree  Woman   \n",
       "1758                        College degree  Woman   \n",
       "1759                       Master's degree  Woman   \n",
       "1764                       Master's degree  Woman   \n",
       "...                                    ...    ...   \n",
       "331708  Professional degree (MD, JD, etc.)  Woman   \n",
       "332165                      College degree  Woman   \n",
       "333066                     Master's degree  Woman   \n",
       "333327                         High School  Woman   \n",
       "333411                      College degree    Man   \n",
       "\n",
       "                                                     race  total_salary  \n",
       "480                                                 White       68000.0  \n",
       "1750                                                White       92400.0  \n",
       "1758    Another option not listed here or prefer not t...       88000.0  \n",
       "1759                                                White       71000.0  \n",
       "1764                                                White       65000.0  \n",
       "...                                                   ...           ...  \n",
       "331708                                                NaN      160332.0  \n",
       "332165                                              White       57000.0  \n",
       "333066                                              White       52416.0  \n",
       "333327                            Asian or Asian American       40000.0  \n",
       "333411                Hispanic, Latino, or Spanish origin       75000.0  \n",
       "\n",
       "[1444 rows x 19 columns]>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[(df_clean['country'] == 'united states') & (df_clean['state'].isna())].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was the practice run , now implemtned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes common words describing city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['city'] = df_clean.apply(lambda row: ' '.join([word for word in row['city'].split() if word.lower() not in common_city_use]) if isinstance(row['city'], str) else row['city'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = df_clean['state'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_list  =df_city_mapping_abbrev['state_name']\n",
    "us_state_list = us_state_list.drop_duplicates()\n",
    "us_state_list = us_state_list.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this also needs to be placed higher up, it places the city in the state column if it already exists in the state list\n",
    "# created from unique values in state column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['state'] =  df_clean.apply(lambda row: row['city'] if isinstance(row['city'],str) and row['city'] in state_list else row['state'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df clean state equal to city , city shold be nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['city'] = df_clean.apply(lambda row: np.nan if row['city'] != 'new york' and row['state']==row['city'] else row['city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['city'] = df_clean.apply(lambda row: row['city'].replace('.','') if isinstance(row['city'],str) and '.' in row['city'] else row['city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['city'] = df_clean.apply(lambda row: row['city'].replace(',','') if isinstance(row['city'],str) and pd.notna(row['city']) and ',' in row['city'] else row['city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the second element of city split is a state , put it in state column \n",
    "# portland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['state'] = df_clean.apply(lambda row: row['city'].split()[1] \n",
    "                                   if isinstance(row['city'],str) \n",
    "                                   and len(row['city'].split())==2 \n",
    "                                   and row['city'].split()[1] in us_state_list \n",
    "                                   else row['state']\n",
    "                                   ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning multiple new york entries\n",
    "df_clean['city'] = df_clean.apply(lambda row: 'new york city' if row['city'] in ['new york', 'nyc','new york ny'] else row['city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you did all this without relizing that\n",
    "# portland city still doesnt have state\n",
    "# going to redo the process of merging states on city where country = united states\n",
    "# replacing the state value with the new merge value if there isnt a state already "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean_test = df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean_test = pd.merge(df_clean_test,df_city_mapping,how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean_test['state'] = df_clean_test.apply(lambda row: row['state_name'] \n",
    "#                                             if pd.isna(row['state'])\n",
    "#                                             and isinstance(row['state_name'],str)\n",
    "#                                             and row['country'] == 'united states'\n",
    "#                                             else row['state']\n",
    "#                                             ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['city'] = df_clean.apply(lambda row: 'san francisco' if row['city'] in ['sf','sf bay','san francisco bay'] else row['city'],axis=1)\n",
    "df_clean['state'] = df_clean.apply(lambda row: 'california' if row['city'] == 'san francisco' else row['state'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly you have just abbrev for state name left in city column \n",
    "# unique answers in state city column that have a state already need to be cleaned somehow \n",
    "# you need to make sure that all dc / district of columbia answers are all uniform and not all random bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean1 = df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test merge for state id on test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming column to match mapping dataframe\n",
    "df_clean1.rename(columns={'city':'state_id'},inplace='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging test dataframe on mapping dataframe \n",
    "df_clean1 = pd.merge(df_clean1, df_abbrev_clean, on='state_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placing merged state on state row if there is one that exists and there is no state that exists\n",
    "df_clean1['state'] = df_clean1.apply(lambda row: row['state_name']\n",
    "                                    if isinstance(row['state_name'], str)\n",
    "                                    and pd.isna(row['state'])\n",
    "                                    and ~pd.notna(row['state_name'])\n",
    "                                    else row['state']\n",
    "                                    ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the added rows \n",
    "df_clean1.drop(labels =['state_name',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column state id back to city since we are done with the merg e\n",
    "df_clean1.rename(columns={'state_id':'city'},inplace='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets go ahead and do the final cleaning \n",
    "## dropping rows that are not going to be used for the final dashboard because they are too niche to clean further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a row in the united states has no state, city should be nan\n",
    "df_clean1['city'] = df_clean1.apply(lambda row: np.nan \n",
    "                                    if pd.isna(row['state']) \n",
    "                                    and row['country'] in 'united states' \n",
    "                                    else row['city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USD', 'GBP', 'CAD', 'EUR', 'AUD/NZD', 'INR', 'RMB', 'CHF', 'MYR',\n",
       "       'ZAR', 'SEK', 'HKD', 'KWD', 'NOK', 'NA ', 'BR$', 'DKK', 'COP',\n",
       "       'TTD', 'BRL', 'MXN', 'CZK', 'BDT', 'PHP', 'PLN', 'TRY', 'CNY',\n",
       "       'ILS', 'AUD', 'JPY', 'TWD', 'NZD', 'SGD', 'THB', 'IDR', 'LKR',\n",
       "       'EQUITY', 'ARS', 'KRW', 'SAR', 'NTD', 'N/A', 'HRK', 'NGN', 'PKR'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing all types of currencies\n",
    "df_clean1['currency'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating exchange rates into usd \n",
    "exchange_rates = {'USD': 1, 'EUR': 1.12, 'GBP': 1.26, 'JPY': 0.0067,\n",
    "                  'AUD/NZD':.65,'INR':.021,'RMB':.14,'CHF':1.15,\n",
    "                  'MYR':.21,'ZAR':.053,'SEK':.095,'HKD':0.13,\n",
    "                  'TTD':0.15,'BRL':.2,'MXN':.058,'CZK':.043,\n",
    "                  'BDT':0.0091,'PHP':0.018,'PLN':0.25,'TRY':0.033,\n",
    "                  'CNY':0.14,'ILS':0.27,'AUD':0.65,'JPY':0.0067,\n",
    "                  'SGD':0.74,'NZD':0.61,'THB':0.028,'IDR':0.000064,\n",
    "                  'LKR':0.0032,'ARS':0.0012,'KRW':0.00075,'SAR':0.27,\n",
    "                  'NTD':0.032,'HRK':0.144342,'NGN':0.0011,'PKR':0.0036,\n",
    "                  'CAD':0.74,'KWD':3.25,'NOK':0.094,'N/A':np.nan,\n",
    "                  'EQUITY':np.nan,'DKK':0.14,'COP':0.00026}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping function to mutiply total salary by the matching exchange rate given by currency column to make it all usd\n",
    "def convert_to_usd(row):\n",
    "    if row['currency'] in exchange_rates:\n",
    "        return row['total_salary'] * exchange_rates[row['currency']]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean1['amount_usd'] = df_clean1.apply(convert_to_usd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to select rows that are in the us with empty state \n",
    "df_clean1 = df_clean1[~((df_clean1['country'] == 'united states') & (df_clean1['state'].isna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if city == country remove city \n",
    "df_clean1['city'] = df_clean1.apply(lambda row: np.nan\n",
    "                             if isinstance(row['city'],str)\n",
    "                             and isinstance(row['country'],str)\n",
    "                             and row['city'] in row['country']\n",
    "                             else row['city']\n",
    "                             ,axis=1\n",
    "\n",
    "                            \n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly , using just the top 100 results by volumn for the job title so there arent 1k options for the dashboard \n",
    "# Assuming your DataFrame is named 'df' and the job title column is named 'job_title'\n",
    "top_100_job_titles = df_clean1['job title'].value_counts().head(100).index\n",
    "\n",
    "# Filter the DataFrame to include only the rows where the job title is in the top 100\n",
    "df_filtered = df_clean1[df_clean1['job title'].isin(top_100_job_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1079782292.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['income_context'] = df_filtered.apply(lambda row: row['income_context'].replace(',','')\n"
     ]
    }
   ],
   "source": [
    "df_filtered['income_context'] = df_filtered.apply(lambda row: row['income_context'].replace(',','') \n",
    "                                                            if isinstance(row['income_context'],str)\n",
    "                                                            and row['income_context'] in ','\n",
    "                                                            else row['income_context']\n",
    "                                                            ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = ['income_context','other_currency','job_title_context','income_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>job title</th>\n",
       "      <th>salary</th>\n",
       "      <th>compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>professional_experience_overall</th>\n",
       "      <th>professional_experience_in_specified_field</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>total_salary</th>\n",
       "      <th>amount_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>29.5</td>\n",
       "      <td>nonprofits</td>\n",
       "      <td>program manager</td>\n",
       "      <td>62000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>united states</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>milwaukee</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>29.5</td>\n",
       "      <td>accounting, banking &amp; finance</td>\n",
       "      <td>accounting manager</td>\n",
       "      <td>60000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>united states</td>\n",
       "      <td>south carolina</td>\n",
       "      <td>greenville</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4/27/2021 11:03:00</td>\n",
       "      <td>29.5</td>\n",
       "      <td>education (primary/secondary)</td>\n",
       "      <td>librarian</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>united states</td>\n",
       "      <td>arizona</td>\n",
       "      <td>yuma</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>4/27/2021 11:03:02</td>\n",
       "      <td>39.5</td>\n",
       "      <td>accounting, banking &amp; finance</td>\n",
       "      <td>senior accountant</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>united states</td>\n",
       "      <td>florida</td>\n",
       "      <td>palm coast</td>\n",
       "      <td>25.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Hispanic, Latino, or Spanish origin, White</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4/27/2021 11:03:03</td>\n",
       "      <td>29.5</td>\n",
       "      <td>nonprofits</td>\n",
       "      <td>office manager</td>\n",
       "      <td>47500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>united states</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>boston</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>47500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>28042</td>\n",
       "      <td>7/25/2023 15:48:47</td>\n",
       "      <td>29.5</td>\n",
       "      <td>marketing, advertising &amp; pr</td>\n",
       "      <td>product manager</td>\n",
       "      <td>115000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>united states</td>\n",
       "      <td>texas</td>\n",
       "      <td>fort worth</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Some college</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>115000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>28043</td>\n",
       "      <td>8/8/2023 7:12:10</td>\n",
       "      <td>29.5</td>\n",
       "      <td>computing or tech</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>960000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>ghana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accra</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>960000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>28051</td>\n",
       "      <td>9/26/2023 23:30:35</td>\n",
       "      <td>29.5</td>\n",
       "      <td>government and public administration</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>94000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>united states</td>\n",
       "      <td>new york</td>\n",
       "      <td>new york city</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>94000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>28059</td>\n",
       "      <td>10/16/2023 6:58:49</td>\n",
       "      <td>65.0</td>\n",
       "      <td>plumbing</td>\n",
       "      <td>manager</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ZAR</td>\n",
       "      <td>south africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>johannesburg</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>28060</td>\n",
       "      <td>10/16/2023 7:07:11</td>\n",
       "      <td>65.0</td>\n",
       "      <td>plumbing</td>\n",
       "      <td>manager</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>ZAR</td>\n",
       "      <td>south africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>johannesburg</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6293 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index           timestamp   age                              industry  \\\n",
       "0         3  4/27/2021 11:02:41  29.5                            nonprofits   \n",
       "1         4  4/27/2021 11:02:42  29.5         accounting, banking & finance   \n",
       "2         7  4/27/2021 11:03:00  29.5         education (primary/secondary)   \n",
       "3         9  4/27/2021 11:03:02  39.5         accounting, banking & finance   \n",
       "4        10  4/27/2021 11:03:03  29.5                            nonprofits   \n",
       "...     ...                 ...   ...                                   ...   \n",
       "6288  28042  7/25/2023 15:48:47  29.5           marketing, advertising & pr   \n",
       "6289  28043    8/8/2023 7:12:10  29.5                     computing or tech   \n",
       "6290  28051  9/26/2023 23:30:35  29.5  government and public administration   \n",
       "6291  28059  10/16/2023 6:58:49  65.0                              plumbing   \n",
       "6292  28060  10/16/2023 7:07:11  65.0                              plumbing   \n",
       "\n",
       "               job title  salary  compensation currency        country  \\\n",
       "0        program manager   62000        3000.0      USD  united states   \n",
       "1     accounting manager   60000        7000.0      USD  united states   \n",
       "2              librarian   50000           0.0      USD  united states   \n",
       "3      senior accountant   45000           0.0      USD  united states   \n",
       "4         office manager   47500           0.0      USD  united states   \n",
       "...                  ...     ...           ...      ...            ...   \n",
       "6288     product manager  115000           0.0      USD  united states   \n",
       "6289      data scientist  960000           0.0      USD          ghana   \n",
       "6290      data scientist   94000           0.0      USD  united states   \n",
       "6291             manager   30000       10000.0      ZAR   south africa   \n",
       "6292             manager   30000       10000.0      ZAR   south africa   \n",
       "\n",
       "               state           city  professional_experience_overall  \\\n",
       "0          wisconsin      milwaukee                              9.0   \n",
       "1     south carolina     greenville                              9.0   \n",
       "2            arizona           yuma                              6.0   \n",
       "3            florida     palm coast                             25.5   \n",
       "4      massachusetts        boston                               6.0   \n",
       "...              ...            ...                              ...   \n",
       "6288           texas     fort worth                              9.0   \n",
       "6289             NaN          accra                              3.0   \n",
       "6290        new york  new york city                              9.0   \n",
       "6291             NaN   johannesburg                             41.0   \n",
       "6292             NaN   johannesburg                             41.0   \n",
       "\n",
       "      professional_experience_in_specified_field        education gender  \\\n",
       "0                                            6.0   College degree  Woman   \n",
       "1                                            6.0   College degree  Woman   \n",
       "2                                            6.0  Master's degree    Man   \n",
       "3                                           25.5   College degree  Woman   \n",
       "4                                            6.0   College degree  Woman   \n",
       "...                                          ...              ...    ...   \n",
       "6288                                         9.0     Some college    Man   \n",
       "6289                                         3.0   College degree    Man   \n",
       "6290                                         3.0  Master's degree  Woman   \n",
       "6291                                        41.0      High School    Man   \n",
       "6292                                        41.0              NaN    Man   \n",
       "\n",
       "                                            race  total_salary  amount_usd  \n",
       "0                                          White       65000.0     65000.0  \n",
       "1                                          White       67000.0     67000.0  \n",
       "2                                          White       50000.0     50000.0  \n",
       "3     Hispanic, Latino, or Spanish origin, White       45000.0     45000.0  \n",
       "4                                          White       47500.0     47500.0  \n",
       "...                                          ...           ...         ...  \n",
       "6288                                       White      115000.0    115000.0  \n",
       "6289                   Black or African American      960000.0    960000.0  \n",
       "6290                                         NaN       94000.0     94000.0  \n",
       "6291                                       White       40000.0      2120.0  \n",
       "6292                                       White       40000.0      2120.0  \n",
       "\n",
       "[6293 rows x 18 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping excess rows to see if it allows it to parse on looker studio \n",
    "df_filtered.drop(rows_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ready to save work and start building dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewg\\AppData\\Local\\Temp\\ipykernel_9156\\1440391151.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['gender'] = df_filtered.apply(lambda row: 'Other or prefer not to answer' if pd.isnull(row['gender']) else row['gender'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# if gender is nan it should be pref not to answer \n",
    "df_filtered['gender'] = df_filtered.apply(lambda row: 'Other or prefer not to answer' if pd.isnull(row['gender']) else row['gender'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commenting save out for time being while you explore errors found while building dashboard\n",
    "# you dont want to go and save it again because last time you had 10 errors you had to fix manually before\n",
    "# looker studio would accept it and i dont want to do that process over again. \n",
    "\n",
    "\n",
    "#df_filtered.to_csv('cleaned_dirty_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Hispanic, Latino, or Spanish origin, White',\n",
       "       'Asian or Asian American',\n",
       "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, White',\n",
       "       'Black or African American',\n",
       "       'Another option not listed here or prefer not to answer', nan,\n",
       "       'Native American or Alaska Native',\n",
       "       'Asian or Asian American, White',\n",
       "       'Black or African American, Native American or Alaska Native, White',\n",
       "       'Middle Eastern or Northern African, White',\n",
       "       'Black or African American, Hispanic, Latino, or Spanish origin, White',\n",
       "       'Hispanic, Latino, or Spanish origin',\n",
       "       'Native American or Alaska Native, White',\n",
       "       'Black or African American, White',\n",
       "       'White, Another option not listed here or prefer not to answer',\n",
       "       'Middle Eastern or Northern African',\n",
       "       'Black or African American, Hispanic, Latino, or Spanish origin',\n",
       "       'Asian or Asian American, Black or African American',\n",
       "       'Asian or Asian American, Hispanic, Latino, or Spanish origin',\n",
       "       'Asian or Asian American, Another option not listed here or prefer not to answer',\n",
       "       'Asian or Asian American, Black or African American, White',\n",
       "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native',\n",
       "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African',\n",
       "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White',\n",
       "       'Asian or Asian American, White, Another option not listed here or prefer not to answer',\n",
       "       'Asian or Asian American, Middle Eastern or Northern African',\n",
       "       'Black or African American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
       "       'Asian or Asian American, Middle Eastern or Northern African, White',\n",
       "       'Middle Eastern or Northern African, White, Another option not listed here or prefer not to answer',\n",
       "       'Black or African American, Middle Eastern or Northern African, White',\n",
       "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking unique \n",
    "df_filtered['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df clean canada still has state abbrev on end of city "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning neatherlands, removing the from country where its the netherlands for consistancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['country'] = df_clean.apply(lambda row: row['country'].replace('the','') if row['country']=='the netherlands' else row['country'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all unique states\n",
    "# replace values in state column if state exists within city column\n",
    "# going to do this with split and seeing if its in the other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'else' after 'if' expression (3607764913.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[240], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    df['state'] = df.apply(lambda row: row['city'].split()[0] if row['city'].split()[0] in )\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected 'else' after 'if' expression\n"
     ]
    }
   ],
   "source": [
    "# if the state exists as either split in the city column , place it in the state column if there is no value there\n",
    "df['state'] = df.apply(lambda row: row['city'].split()[0] if row['city'].split()[0] in )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to figure out the mapping in city work where you do the san fran / chicagoland stuff without bricking program\n",
    "# need to check if just state abbrev is in city column then put that to state \n",
    "# there has to be a way to see if either split of the city column contains either abbrev or full state and then replace it with nothing\n",
    "# then i think you are ready to start building dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are lots of rows with mulitple entries. For sake of maintaining data quality \n",
    "# i think it would be in the best interest to remove these rows. \n",
    "# maybe further investigation is needed into rows containing more than 1 element to see if there \n",
    "# is a reason why "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a way to add the salary and comp to a new column without bricking everything X\n",
    "# find a way to add the other currency into the main currency column without bricking X\n",
    "# keep all currency columns so you can see salary, comp, and combined X\n",
    "# need to check for a way to see if there is something already currently in the main currency column to avoid overwriting ? X\n",
    "# are you going to have to find a way to sort through the other currency to find descrpencies that are the same thing ie abbevation and string ? ie USD and united states dollar X\n",
    "# look into job title field? look at value counts? search doing soemthing like engineer% to see everything that contains engineer? to see if there is any overlap?\n",
    "# Need to remove commas from salary X \n",
    "# other currency needs to be lowered X\n",
    "# experience fields need to be cleaned ie '5-7 years' needs to be 6.  X\n",
    "# lower country column \n",
    "# country column has us, usa ,U.S.,U.S.A  united states, united states of america etc.\n",
    "# there is also lots of uk and u.k . Is there going to be a way to filter the data ? example - if x contains 'united' x = usa\n",
    "# or regex somehow like u%s%%a = usa . Is that going to have errors? maybe create dataframe on these characteristics first before changing anything\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
